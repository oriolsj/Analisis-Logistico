---
title: "Analisis Logilistico"
author: "Oriol"
date: "2024-04-15"
output: html_document
---

```{r}
#install.packages("gtsummary")
#install.packages("xgboost")
#install.packages("caret")
#install.packages("tidyverse")
library(gtsummary)
library(tidyverse)
library(caret)
library(xgboost)
library(dplyr) ## Para los select
#library("git")
set.seed(Sys.time())
library(ggplot2) #Para plotear
library(pROC)
```

## Carga de los datos 

Cargamos los datos que ya estan filtrados por el script de Python

```{r}
data <- read.csv("sinrepetidos.txt", header = T, sep = "\t")

#colnames(data)
```

## Analisis estadistico 

Vamos a estudiar el dataset para hacernos una idea de lo tenemos y ver que variables son las que potencialmente nos pueden ofrecer información al respecto del mismo.

```{r}
ggplot(data) +
  aes(x = Sexo.del.Paciente, y = Edad.del.Paciente) +
  geom_boxplot(fill = "#0c4c8a") +
  theme_minimal()
```

```{r}
shapiro.test(subset(data, Sexo.del.Paciente == "F")$Edad.del.Paciente)
shapiro.test(subset(data, Sexo.del.Paciente == "M")$Edad.del.Paciente)
```

```{r}
#shapiro.test(subset(data, Penicilina...Sensibilidad == "Sensible")$Edad.del.Paciente)

#subset(data,Penicilina...Sensibilidad)$Edad.del.Paciente
```

### Factorizamos las sensibilidad

En este ejemplo lo realizamos para la Penicilina, más tarde se generaliza al resto de medicamentos.


```{r}
factores<- factor(data$Penicilina...Sensibilidad, exclude = NaN)
factores
```

Una vez obtenido los factores (Sensible - Resistente), ahora asignamos a cada uno un valor (0 o 1). Tambien vamos a asignar un peso a cada paciente acorde a los datos de la media española para hombres y mujeres.

```{r}
factor(data$Penicilina...Sensibilidad, exclude = NaN)
Penicilina <-  data$Penicilina...Sensibilidad
data$Penicilina...Sensibilidad <- unclass(factor(data$Penicilina...Sensibilidad, exclude = NaN))

length(data$Sexo.del.Paciente[data$Sexo.del.Paciente == "F"])

data$Peso[data$Sexo.del.Paciente == "F"] <- rnorm(69, 63, 10)
data$Peso[data$Sexo.del.Paciente == "M"] <- rnorm(160, 75.8, 10)

data$Penicilina...Sensibilidad[data$Penicilina...Sensibilidad == 1] = NaN
```


```{r}
#test <- wilcox.test(data$Penicilina...Sensibilidad ~ data$Sexo.del.Paciente, alternative = "two.sided")
#test
```


# Tener en cuenta que entre variables categoricas hay que hacer un tipo de test (wilcox). Entre variable continua y categorica otro (kruskal) y entre continuas otro (Xi cuadrado o t-test)

Hagamos un estudio de las correlaciones para ver si existen algun sesgo de las variables.

```{r}
dataparacorr <- data.frame(data$Penicilina...Sensibilidad, data$Sexo.del.Paciente, data$Edad.del.Paciente, data$Peso 
                           )
colnames(dataparacorr) <- c("Penicilina...Sensibilidad", "Sexo.del.Paciente","Edad.del.Paciente", "Peso")
dataparacorr <- na.omit(dataparacorr)

CHIS <- lapply(dataparacorr[,-1], function(x) chisq.test(dataparacorr[,1], x ))
do.call(rbind, CHIS)[,c(1,3)]
```

En principio, las correlaciones están por encima del valor del p-value = 0.05. Por tanto, se puede asumir con relativa seguridad que las variables son independientes en su origen. 

```{r}
dataparacorr$Sexo.del.Paciente[dataparacorr$Sexo.del.Paciente == "M"] = 0
dataparacorr$Sexo.del.Paciente[dataparacorr$Sexo.del.Paciente == "F"] = 1

dataparacorr[,2] <- as.numeric(dataparacorr[,2])

WIL <- wilcox.test(dataparacorr$Penicilina...Sensibilidad, dataparacorr$Sexo.del.Paciente)
WIL
KRUS <- lapply(dataparacorr[,2:4],  function(x) kruskal.test( dataparacorr$Penicilina...Sensibilidad, x) )
do.call(rbind, KRUS)[,c(1,3)]
```


# GLM por Antibiotico.

```{r}
results <- glm(Penicilina...Sensibilidad ~ Edad.del.Paciente+Sexo.del.Paciente+Peso , data, na.action = na.omit, family =quasi())
summary(results)
```



## Construccion de la confusion matrix y metricas para un antibiotico


```{r}
dataAuxiliar <- data.frame(data$Penicilina...Sensibilidad, data$Sexo.del.Paciente, data$Edad.del.Paciente, data$Peso)
dataAuxiliar <- na.omit(dataAuxiliar)

results <- glm(data.Penicilina...Sensibilidad ~ data.Edad.del.Paciente+data.Sexo.del.Paciente+data.Peso , dataAuxiliar, family =quasi())

#results$fitted.values
threshold_2 <- 2.5

predictions <- dataAuxiliar %>% 
  mutate(pred.fit = results$fitted.values,
    predicted_class = if_else(pred.fit > threshold_2, 3, 2),
    correct = if_else( predicted_class == data.Penicilina...Sensibilidad, 'correct', 'incorrect')
  )

# Construimos la  confusion matrix
confusion_matrix <- table(predictions$data.Penicilina...Sensibilidad, predictions$predicted_class)
tn <- confusion_matrix["2", "2"]  # True Negatives
tp <- confusion_matrix["3", "3"]  # True Positives
fn <- confusion_matrix["3", "2"]  # False Negatives
fp <- confusion_matrix["2", "3"]  # False Positives

# Calculate accuracy La métrica de precisión es utilizada para poder saber qué porcentaje de valores que se han clasificado como positivos son realmente positivos.
accuracy <- (tp + tn) / (tp + tn + fp + fn)

# Calculate precision La métrica de precisión es utilizada para poder saber qué porcentaje de valores que se han clasificado como positivos son realmente positivos.
precision <- tp / (tp + fp)

# Calculamos el recall La métrica de recall, también conocida como el ratio de verdaderos positivos, es utilizada para saber cuantos valores positivos son correctamente clasificados.
recall <- tp / (tp + fn)

Sensitivity <- recall

Specificity <- tn/(tn+fp)

#Cohen’s kappa  compares how well the binary classifier performs compared to the randomized accuracy  it can be applied to measure the agreement between the predicted and the real classes.

p_e <- ((tp+fn)*(tp+fp) + (tn+fp)*(tn+fn))/((tp+fp+tn+fn)**2)
kappa <- (accuracy-p_e)/(1-p_e)

#F1 score

F1 <- 2 * ((recall * precision)/(recall + precision))

cat("Metricas:\n")
cat("Accuracy: ", accuracy, "\t", "Precision: ", precision, "\t", "Recall: ", recall, "\t", "F1 Score: ", F1, "\n")

# Cambiamos nombres a las columnas de la confusion matrix
confusion_matrix_named <- matrix(c(tn, fp, fn, tp),
                                 nrow = 2,
                                 dimnames = list('Actual' = c('Resistente', 'Sensible'),
                                                 'Predicted' = c('Resistente', 'Sensible')))
```

```{r}
# Function to draw the confusion matrix
draw_confusion_matrix <- function(cm, name) {
  layout(matrix(c(1,1,2)))
  par(mar=c(2,2,2,2))
  plot(c(100, 345), c(300, 450), type = "n", xlab="", ylab="", xaxt='n', yaxt='n')
  title(paste0('CONFUSION MATRIX of ', name), cex.main=2)
  
  # Create the matrix 
  rect(150, 430, 240, 370, col='#3F97D0')
  text(195, 435, 'Resistente', cex=1.2)
  rect(250, 430, 340, 370, col='#F7AD50')
  text(295, 435, 'Sensible', cex=1.2)
  text(125, 370, 'Predicted', cex=1.3, srt=90, font=2)
  text(245, 450, 'Actual', cex=1.3, font=2)
  rect(150, 305, 240, 365, col='#F7AD50')
  rect(250, 305, 340, 365, col='#3F97D0')
  text(140, 400, 'Resistente', cex=1.2, srt=90)
  text(140, 335, 'Sensible', cex=1.2, srt=90)
  
  # Add in the confusion matrix results 
  res <- as.numeric(cm)
  text(195, 400, res[1], cex=1.6, font=2, col='white')
  text(195, 335, res[2], cex=1.6, font=2, col='white')
  text(295, 400, res[3], cex=1.6, font=2, col='white')
  text(295, 335, res[4], cex=1.6, font=2, col='white')
  tn <- cm[1, 1]  # True Negatives
  tp <- cm[2, 2]  # True Positives
  fn <- cm[2, 1]  # False Negatives
  fp <- cm[1, 2]  # False Positives
  Acc <- (tp + tn) / (tp + tn + fp + fn)
  Prec <- tp / (tp + fp)
  Rec <- tp / (tp + fn)
  Sens <- recall
  Spec <- tn/(tn+fp)
  p_e <- ((tp+fn)*(tp+fp) + (tn+fp)*(tn+fn))/((tp+fp+tn+fn)**2)
  kappa <- (accuracy-p_e)/(1-p_e)
  F1 <- 2 * ((Rec * Prec)/(Rec + Prec))

  # Add in the specifics 
  plot(c(100, 0), c(100, 0), type = "n", xlab="", ylab="", main = "DETAILS", xaxt='n', yaxt='n')
  text(10, 85, "Sensitivity", cex=1.2, font=2)
  text(10, 70, round(Sens, 3), cex=1.2)
  text(30, 85, "Specifity", cex=1.2, font=2)
  text(30, 70, round(Spec, 3), cex=1.2)
  text(50, 85, "Precision", cex=1.2, font=2)
  text(50, 70, round(Prec, 3), cex=1.2)
  text(70, 85, "recall", cex=1.2, font=2)
  text(70, 70, round(Rec, 3), cex=1.2)
  text(90, 85, "F1 score", cex=1.2, font=2)
  text(90, 70, round(F1, 3), cex=1.2)
  
  # Add in the accuracy information 
  text(30, 35, "Accuracy", cex=1.5, font=2)
  text(30, 20, round(Acc, 3), cex=1.4)
  text(60, 35, "Cohen's Kappa", cex=1.5, font=2)
  text(60, 20, round(kappa, 3), cex=1.4)
}

# Draw the confusion matrix
draw_confusion_matrix(confusion_matrix, "Penicilina")
```

### Aerea debajo de la curva Roc

```{r}
roc_curve <- roc(predictions$data.Penicilina...Sensibilidad, predictions$pred.fit, levels = c(2, 3), direction = "<")
auroc <- auc(roc_curve)

# Print the AUROC
cat("AUROC: ", auroc, "\n")
# Create a data frame from the ROC curve
roc_df <- data.frame(
  tpr = roc_curve$sensitivities,  # True Positive Rate
  fpr = 1 - roc_curve$specificities  # False Positive Rate
)

# Plot the ROC curve using ggplot2
pl1 <- ggplot(roc_df, aes(x = fpr, y = tpr)) +
  geom_line(color = "blue") +
  geom_abline(linetype = "dashed", color = "red") +
  labs(
    title = "ROC Curve",
    x = "False Positive Rate",
    y = "True Positive Rate"
  )

# Display the plot
#pl1
```


### Prediccion con datos inventados 


```{r}
new_obs <- data.frame(data.Edad.del.Paciente = c(42,65), data.Sexo.del.Paciente = c("M","F"),
                      data.Peso = c(65, 53) )

predict(
  results, 
  newdata = new_obs,
  type = 'response'
)
```



```{r}
results %>% 
  tbl_regression(intercept=TRUE, conf.level=0.9) %>%
  add_glance_source_note() %>%
  add_global_p() %>%
  add_q() 
#predict(modelo_results,dataset.test)
```



```{r}
par(mfrow = c(2,2))
plot(results)
```

# Generalizacion a todas las descripciones

```{r}
descripciones <- unique(data$Descripción)
data$Penicilina...Sensibilidad <- Penicilina

medicamentos <- colnames( select(data, contains("Sensibilidad")))
```

```{r,  warning= TRUE}
#### Warnings por coercion, por tratar variables logicas a numericas ####

##data$Penicilina...Sensibilidad <- unclass(factor(data$Penicilina...Sensibilidad, exclude = NaN))

for (j in medicamentos) {  ##Cada vez que encuentra una celda vacia problemas
  if( sum(is.na(data[[j]])) == length(data[[j]]) ){ #Si es nula la obviamos del analisis
           next;
  }else{
    data[[j]] <- unclass( factor(data[[j]], levels = c("Sensible","Sensible EI","Resistente") , exclude = c(NaN,NA,"") ))
  }
}
```

```{r} 
### Metodo unclass pero no podemos ignorar los NANs

#for (i in medicamentos){ ##Factorizamos y asignamos valor a la variable categorica    unclass(data$i)
#    data[[i]] <- unclass( factor(data[[i]] , exclude = NaN))
#    data[[i]][ data[[i]] == 1 ] = NaN
#}
```

### Generalizacion a todas las descripciones y medicamentos

```{r}
results_frame <- list()  #Actualizar para poder guardar con cada descripcion un lista de dataframes de medicamentos
predictions <- list()
confusions_matrices <- list()

for(i in descripciones){
  if ( sum(data$Descripción == i) < 20 ){ #Filtramos para ver si hay cantidad suficiente de datos para hacer estadistica
    next;
  }else{
    print(i)
    results_frame[[i]] <- list()
    data_Aux = data[ data$Descripción == i,] #Lista auxiliar en funcion del organismo
    for(j in medicamentos){ #Columnas correspondientes sensibilidad de cada medicamentos
        data_Aux_j <- data_Aux[!is.na(data_Aux[[j]]), ] # Quitamos filas sin sensibilidad de ese medicamento
        dataAuxiliar <- data.frame( a = data_Aux_j[[j]], 
                                    Sexo.del.Paciente= data_Aux_j$Sexo.del.Paciente,  
                                    Edad.del.Paciente= data_Aux_j$Edad.del.Paciente, 
                                    Peso= data_Aux_j$Peso)
        
        names(dataAuxiliar)[names(dataAuxiliar) == 'a'] <- paste0(j)
        #dataAuxiliar <- dataAuxiliar %>% rename_at('a', ~ deparse(j))
        if( length(dataAuxiliar$Peso) < 20){ #Si hay menos de 10 casos tambien obviamos el analisis
           next;
         }else {
            #print(j)
            results <- glm(formula = paste0(j ," ~ Edad.del.Paciente*Sexo.del.Paciente+Peso"), data_Aux_j, 
                           family = quasi() ) #Modelo 
            
            results_frame[[i]][[j]]<- coef(summary(results)) #Guardamos los resultados en una lista de listas
            
            predictions[[i]][[j]] <- dataAuxiliar %>% 
                          mutate(pred.fit = results$fitted.values,
                            predicted_class = if_else(pred.fit > 2.0, 3, 2), #threshold is 2 
                            correct = if_else( predicted_class == data_Aux_j[[j]], 'correct', 'incorrect')
                          )

            # Construimos la  confusion matrix
            
            cm <- matrix(0, nrow = 2, ncol = 2, dimnames = list(Actual = c('2', '3'), Predicted = c('2', '3')))
            
            # Populate the confusion matrix
            actual <- factor(predictions[[i]][[j]][[j]], levels = c(2, 3))
            predicted <- factor(predictions[[i]][[j]]$predicted_class, levels = c(2, 3))
            cm <- table(actual, predicted)
            
            confusions_matrices[[i]][[j]] <- cm
            draw_confusion_matrix(cm, j)
        }
    }
    cat("\n")
  }
}
```



```{r, echo = T, results = 'hide'}
#for (i in descripciones) {
#  print(c(i, nrow(data[ data$Descripción == i, ] ) ))
#}
```


```{r}
data_Staph = data[ data$Descripción == "Staphylococcus epidermidis",]

results <- glm(Penicilina...Sensibilidad ~ Edad.del.Paciente+Sexo.del.Paciente+Peso, data_Staph, na.action = na.omit,family =quasi())
summary(results)

```

```{r}
par(mfrow = c(2,2))
plot(results)
```

```{r}
data_haem = data[ data$Descripción == "Staphylococcus haemolyticus",]

results <- glm(Penicilina...Sensibilidad ~ Edad.del.Paciente+Sexo.del.Paciente+Peso, data_haem, na.action = na.omit,family =quasi())
#summary(results)
```

# Arbol de decisiones

Primero incluimos la libreria:

```{r}
library(rpart)
```


Probamos con el organismo para el cual hay más pacientes. Y un tipo de medicamento con una distribución en la cual apaarecen las tres posibilidades de sensibilidad. 

```{r}
data_epi = data[ data$Descripción == "Staphylococcus epidermidis",]

tree_model <- rpart(Linezolid...Sensibilidad ~ Edad.del.Paciente + Sexo.del.Paciente + Peso, data = data_epi, na.action = na.omit)

summary(tree_model)
```

Ahora, podemos modificar el bucle para calcular los modelos logisticos y asi generalizar para los arboles de decisión, cambiando los nombres de las variables para guardar los resultados. 

```{r}
results_trees <- list()  #Actualizar para poder guardar con cada descripcion un lista de dataframes de medicamentos

trees_confusions_matrices <- list()

for(i in descripciones){
  if ( sum(data$Descripción == i) < 20 ){ #Filtramos para ver si hay cantidad suficiente de datos para hacer estadistica
    next;
  }else{
    results_frame[[i]] <- list()
    data_Aux = data[ data$Descripción == i,] #Lista auxiliar en funcion del organismo
    for(j in medicamentos){ #Columnas correspondientes sensibilidad de cada medicamentos
        data_Aux_j <- data_Aux[!is.na(data_Aux[[j]]), ] # Quitamos filas sin sensibilidad de ese medicamento
        dataAuxiliar <- data.frame( a = data_Aux_j[[j]], 
                                    Sexo.del.Paciente= data_Aux_j$Sexo.del.Paciente,  
                                    Edad.del.Paciente= data_Aux_j$Edad.del.Paciente, 
                                    Peso = data_Aux_j$Peso)
        
        names(dataAuxiliar)[names(dataAuxiliar) == 'a'] <- paste0(j)
        #dataAuxiliar <- dataAuxiliar %>% rename_at('a', ~ deparse(j))
        if( length(dataAuxiliar$Peso) < 20){ #Si hay menos de 10 casos tambien obviamos el analisis
           next;
         }else {
            #print(j)
            tree_model <- rpart(formula = paste0(j ," ~ Edad.del.Paciente+Sexo.del.Paciente+Peso"), data = dataAuxiliar)
            results_trees[[i]][[j]]<- tree_model #Guardamos los resultados en una lista de listas
            
            
            
            predictions[[i]][[j]] <- dataAuxiliar %>% 
                          mutate(pred.fit = predict( tree_model, dataAuxiliar),
                            predicted_class = if_else(pred.fit > 2.0, 3, 2), #threshold is 2 
                            correct = if_else( predicted_class == dataAuxiliar[[j]], 'correct', 'incorrect')
                          )

            # Construimos la  confusion matrix
            
            cm <- matrix(0, nrow = 2, ncol = 2, dimnames = list(Actual = c('2', '3'), Predicted = c('2', '3')))
            
            # Populate the confusion matrix
            actual <- factor(predictions[[i]][[j]][[j]], levels = c(2, 3))
            predicted <- factor(predictions[[i]][[j]]$predicted_class, levels = c(2, 3))
            cm <- table(actual, predicted)
            
            trees_confusions_matrices[[i]][[j]] <- cm
            draw_confusion_matrix(cm, j)
         }
      }
  }
}
```



```{r}
# Plot the tree
plot(tree_model)
text(tree_model, use.n = TRUE)
```

### Redes neuronales 

Vamos ahora a proponer redes neuronales para resolver el problema. Usaremos la libreria h2o que implementa redes neuronales. 

```{r}
library(h2o)

h2o.init()
```


```{r}
data_Aux.hex <- as.h2o(data_Aux)


data_Aux.hex

modelo_dl_200_200 <- h2o.deeplearning(
                      x = c("Edad.del.Paciente", "Sexo.del.Paciente", "Peso"),
                      y = "Linezolid...Sensibilidad",
                      distribution = "multinomial",
                      training_frame = data_Aux.hex,
                      standardize = TRUE,
                      activation = "Rectifier",
                      hidden = c(200, 200),
                      stopping_rounds = 0,
                      epochs = 100,
                      seed = 123,
                      model_id = "modelo_dl_200_200"
                    )
```



Guardo el antibiograma limpio.
```{r}
#data <- subset(data, select = -c(Servicio))
write.table(data, file = "Antibiogramaclean.csv" , sep = "\t")
```




